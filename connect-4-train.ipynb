{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47046c1",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-04-09T23:11:57.021160Z",
     "iopub.status.busy": "2025-04-09T23:11:57.020727Z",
     "iopub.status.idle": "2025-04-09T23:12:24.926543Z",
     "shell.execute_reply": "2025-04-09T23:12:24.924928Z"
    },
    "papermill": {
     "duration": 27.91259,
     "end_time": "2025-04-09T23:12:24.928792",
     "exception": false,
     "start_time": "2025-04-09T23:11:57.016202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n",
      "  from jax import xla_computation as _xla_computation\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback\n",
    "import copy\n",
    "import random, math\n",
    "import os\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2af66347",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:12:24.937053Z",
     "iopub.status.busy": "2025-04-09T23:12:24.936296Z",
     "iopub.status.idle": "2025-04-09T23:12:39.367629Z",
     "shell.execute_reply": "2025-04-09T23:12:39.366195Z"
    },
    "papermill": {
     "duration": 14.437323,
     "end_time": "2025-04-09T23:12:39.369629",
     "exception": false,
     "start_time": "2025-04-09T23:12:24.932306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.10/dist-packages (2.1.0)\r\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\r\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.5.1+cu121)\r\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.1.0)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.3)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.5)\r\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\r\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (2.4.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.17.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.12.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable_baselines3) (1.3.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.55.3)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.7)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.2)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (11.0.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2025.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->stable_baselines3) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->stable_baselines3) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->stable_baselines3) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->stable_baselines3) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->stable_baselines3) (2024.2.0)\r\n",
      "Cloning into 'connect4_solver_fork'...\r\n",
      "remote: Enumerating objects: 149, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (14/14), done.\u001b[K\r\n",
      "remote: Total 149 (delta 17), reused 13 (delta 13), pack-reused 122 (from 2)\u001b[K\r\n",
      "Receiving objects: 100% (149/149), 67.77 KiB | 4.52 MiB/s, done.\r\n",
      "Resolving deltas: 100% (87/87), done.\r\n",
      "g++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC -MM Solver.cpp > ./.depend\r\n",
      "g++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC   -c -o Solver.o Solver.cpp\r\n",
      "g++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC   -c -o main.o main.cpp\r\n",
      "g++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC  -o c4solver main.o Solver.o \r\n",
      "g++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC   -c -o generator.o generator.cpp\r\n",
      "g++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC  -o generator generator.o \r\n",
      "g++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC   -c -o solver_c_interface.o solver_c_interface.cpp\r\n",
      "g++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC  -shared -o c4solver_c_interface.so solver_c_interface.o Solver.o \r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r\n",
      "100 32.0M  100 32.0M    0     0  28.9M      0  0:00:01  0:00:01 --:--:-- 28.9M\r\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pexpect\n",
    "import ctypes\n",
    "\n",
    "class Connect4Solver:\n",
    "    !pip install stable_baselines3\n",
    "    !git clone https://github.com/TonyCongqianWang/connect4_solver_fork.git && cd connect4_solver_fork && make\n",
    "    !curl -L https://github.com/PascalPons/connect4/releases/download/book/7x6.book --output 7x6.book\n",
    "    solver_path='./connect4_solver_fork/c4solver_c_interface.so'\n",
    "    solver_lib = ctypes.CDLL(solver_path)\n",
    "            \n",
    "    solver_lib.solver_init.argtypes = [ctypes.c_char_p]\n",
    "    solver_lib.solver_init.restype = ctypes.POINTER(ctypes.c_void_p)\n",
    "    \n",
    "    solver_lib.solver_delete.argtypes = [ctypes.POINTER(ctypes.c_void_p)]\n",
    "    solver_lib.solver_delete.restype = None\n",
    "    \n",
    "    solver_lib.solver_solve.argtypes = [ctypes.POINTER(ctypes.c_void_p), ctypes.c_char_p, ctypes.c_bool, ctypes.c_bool, ctypes.c_char_p, ctypes.c_size_t]\n",
    "    solver_lib.solver_solve.restype = ctypes.c_char_p\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the Connect4Solver with the path to the solver executable.\n",
    "\n",
    "        Args:\n",
    "            solver_path (str): Path to the Connect4 solver executable.\n",
    "        \"\"\"\n",
    "        self.MAX_SCORE = 24\n",
    "        self.handle = Connect4Solver.solver_lib.solver_init(None)\n",
    "        self.result_buffer = ctypes.create_string_buffer(256)\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"\n",
    "        Destructor that sends EOF to the solver process.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'child') and self.child is not None:\n",
    "            try:\n",
    "                self.child.sendeof()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def _process_output(self, prompt_str, answer_str):\n",
    "        \"\"\"\n",
    "        Processes the output from the solver.\n",
    "\n",
    "        Args:\n",
    "            prompt_str (str): The prompt string.\n",
    "            answer_str (str): The answer string.\n",
    "\n",
    "        Returns:\n",
    "            list: List of floats representing the processed output.\n",
    "        \"\"\"\n",
    "        if answer_str.startswith(prompt_str):\n",
    "            answer_str = answer_str[len(prompt_str):].strip()\n",
    "            \n",
    "        answer_list = [float(x) for x in answer_str.split()]\n",
    "        return answer_list\n",
    "\n",
    "    def _softmax(self, x, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Calculates a modified softmax that approaches argmax for small temperatures.\n",
    "\n",
    "        For very small temperatures, indices with the maximum value will receive\n",
    "        equal probability, and the rest will receive 0.\n",
    "\n",
    "        Args:\n",
    "            x (list): List of values.\n",
    "            temperature (float): Temperature parameter for softmax.\n",
    "\n",
    "        Returns:\n",
    "            list: List of probabilities.\n",
    "        \"\"\"\n",
    "        if temperature <= 5e-2:  # Consider a very small temperature as argmax\n",
    "            max_val = max(x)\n",
    "            max_indices = [i for i, val in enumerate(x) if val == max_val]\n",
    "            probabilities = [0.0] * len(x)\n",
    "            prob = 1.0 / len(max_indices)\n",
    "            for i in max_indices:\n",
    "                probabilities[i] = prob\n",
    "            return probabilities\n",
    "        else:\n",
    "            e_x = []\n",
    "            for i in x:\n",
    "                exponent = i / temperature\n",
    "                if exponent < -100:\n",
    "                    e_x.append(0.0)\n",
    "                else:\n",
    "                    e_x.append(math.exp(exponent))\n",
    "\n",
    "            sum_e_x = sum(e_x)\n",
    "            if sum_e_x == 0:\n",
    "                return [1.0 / len(x) for _ in range(len(x))]\n",
    "            return [e / sum_e_x for e in e_x]\n",
    "\n",
    "    def _transform(self, data, score_offset):\n",
    "        transformed_data = []\n",
    "        for x in data:\n",
    "            sign = 1 if x > 0 else -1 if x < 0 else 0\n",
    "            if x > -1000:\n",
    "                transformed_x = sign * ((abs(x) + score_offset) / self.MAX_SCORE * 5)\n",
    "            else:\n",
    "                transformed_x = -1000\n",
    "            transformed_data.append(transformed_x)\n",
    "        #print(transformed_data)\n",
    "        return transformed_data\n",
    "\n",
    "    def _random_index(self, softmax_probs):\n",
    "        \"\"\"\n",
    "        Selects a random index based on softmax probabilities.\n",
    "\n",
    "        Args:\n",
    "            softmax_probs (list): List of softmax probabilities.\n",
    "\n",
    "        Returns:\n",
    "            int: Selected index.\n",
    "        \"\"\"\n",
    "        selected_index = np.random.choice(len(softmax_probs), p=softmax_probs)\n",
    "        return selected_index\n",
    "\n",
    "    def get_solver_move(self, move_str, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Gets a move from the solver.\n",
    "\n",
    "        Args:\n",
    "            move_str (str): Move string to send to the solver.\n",
    "            temperature (float): Temperature parameter for softmax.\n",
    "\n",
    "        Returns:\n",
    "            int: Selected move index.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = Connect4Solver.solver_lib.solver_solve(self.handle, move_str.encode(\"utf-8\"), False, True, self.result_buffer, 256)\n",
    "            answer = result.decode()\n",
    "            score_offset = math.floor(len(move_str) / 2)\n",
    "            transformed = self._transform(self._process_output(move_str, answer), score_offset)\n",
    "            probas = self._softmax(transformed, temperature)\n",
    "            #print(f\"{answer}\")\n",
    "            #print(probas)\n",
    "            return self._random_index(probas)\n",
    "        except Exception as e:\n",
    "            print(f\"{e}\")\n",
    "            print(f\"{temperature=}\")\n",
    "            print(f\"{answer=}\")\n",
    "            try:\n",
    "                print(f\"{transformed=}\")\n",
    "                print(f\"{probas=}\")\n",
    "            except:\n",
    "                pass\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9d7aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:12:39.380058Z",
     "iopub.status.busy": "2025-04-09T23:12:39.379630Z",
     "iopub.status.idle": "2025-04-09T23:12:39.387235Z",
     "shell.execute_reply": "2025-04-09T23:12:39.386111Z"
    },
    "papermill": {
     "duration": 0.014593,
     "end_time": "2025-04-09T23:12:39.388908",
     "exception": false,
     "start_time": "2025-04-09T23:12:39.374315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def zip_directories(directory_paths, working_dir):\n",
    "    \"\"\"\n",
    "    Zips the given directories into their parent directory.\n",
    "\n",
    "    Args:\n",
    "        directory_paths (list): A list of paths to directories.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of paths to the created zip files.\n",
    "    \"\"\"\n",
    "    os.makedirs(working_dir, exist_ok=True)\n",
    "    \n",
    "    zip_file_paths = []\n",
    "    for dir_path in directory_paths:\n",
    "        if not os.path.isdir(dir_path):\n",
    "            print(f\"Warning: {dir_path} is not a directory. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        parent_dir = working_dir\n",
    "        dir_name = os.path.basename(dir_path)\n",
    "        zip_file_path = os.path.join(parent_dir, f\"{dir_name}.zip\")\n",
    "\n",
    "        try:\n",
    "            with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "                for root, _, files in os.walk(dir_path):\n",
    "                    for file in files:\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        relative_path = os.path.relpath(file_path, dir_path)\n",
    "                        zipf.write(file_path, relative_path)\n",
    "            zip_file_paths.append(zip_file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error zipping {dir_path}: {e}\")\n",
    "\n",
    "    return zip_file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1902c327",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-04-09T23:12:39.399018Z",
     "iopub.status.busy": "2025-04-09T23:12:39.398635Z",
     "iopub.status.idle": "2025-04-09T23:12:39.418482Z",
     "shell.execute_reply": "2025-04-09T23:12:39.417398Z"
    },
    "papermill": {
     "duration": 0.026946,
     "end_time": "2025-04-09T23:12:39.420309",
     "exception": false,
     "start_time": "2025-04-09T23:12:39.393363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConnectFourEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\", \"ansi\", \"rgb_array\"], \"render_fps\": 1}\n",
    "    def __init__(self, render_mode=None, board_rows=6, board_cols=7):\n",
    "        super(ConnectFourEnv, self).__init__()\n",
    "        self.board_rows = board_rows\n",
    "        self.board_cols = board_cols\n",
    "        self.action_space = spaces.Discrete(self.board_cols)  # Columns to drop a piece\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(2, self.board_rows, self.board_cols), dtype=np.uint8)  # two binary matrices. one for each players stones\n",
    "        self.render_mode = render_mode\n",
    "        self.move_history = \"\"\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed, options=options)\n",
    "        self.board = np.zeros((self.board_rows, self.board_cols), dtype=np.int8)\n",
    "        self.player = 1  # Player 1 starts\n",
    "        self.done = False\n",
    "        self.winner = None\n",
    "        self.turns = 0\n",
    "        self.move_history_str = \"\"\n",
    "        info = {}\n",
    "        return self._get_observation(), info\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.done:\n",
    "            return self._get_observation(), 0, True, False, {}\n",
    "\n",
    "        if not self._is_valid_move(action):\n",
    "            return self._get_observation(), -50, False, False, {}\n",
    "\n",
    "        self._drop_piece(action)\n",
    "        self.move_history_str += str(action + 1)\n",
    "        self.turns += 1\n",
    "\n",
    "        if self._check_win():\n",
    "            self.done = True\n",
    "            self.winner = self.player\n",
    "            reward = 80 + 20 * (len(self.board.flatten()) - self.turns) / len(self.board.flatten())\n",
    "        elif self._check_draw():\n",
    "            self.done = True\n",
    "            reward = 0\n",
    "        else:\n",
    "            reward = 0\n",
    "        self.player *= -1  # Switch players\n",
    "        return  self._get_observation(), reward, self.done, False, {}\n",
    "\n",
    "    def get_valid_moves(self):\n",
    "        valid_moves = []\n",
    "        for col in range(self.board_cols):\n",
    "            if self._is_valid_move(col):\n",
    "                valid_moves.append(col)\n",
    "        return valid_moves\n",
    "\n",
    "    def _get_observation(self):\n",
    "        m, n = self.board.shape\n",
    "        player_perspective = self.board * self.player\n",
    "        new_array = np.zeros((2, m, n), dtype=np.uint8)\n",
    "        new_array[0, :, :] = 255 * (player_perspective == 1).astype(np.uint8)\n",
    "        new_array[1, :, :] = 255 * (player_perspective == -1).astype(np.uint8)\n",
    "        return new_array\n",
    "\n",
    "    def _is_valid_move(self, col):\n",
    "        return self.board[0, col] == 0\n",
    "\n",
    "    def _drop_piece(self, col):\n",
    "        for row in range(self.board_rows - 1, -1, -1):\n",
    "            if self.board[row, col] == 0:\n",
    "                self.board[row, col] = self.player\n",
    "                return\n",
    "\n",
    "    def _check_win(self):\n",
    "        # Check horizontal, vertical, and diagonal wins\n",
    "        for r in range(self.board_rows):\n",
    "            for c in range(self.board_cols - 3):\n",
    "                if (\n",
    "                    self.board[r, c] == self.board[r, c + 1] == self.board[r, c + 2] == self.board[r, c + 3] != 0\n",
    "                ):\n",
    "                    return True\n",
    "\n",
    "        for c in range(self.board_cols):\n",
    "            for r in range(self.board_rows - 3):\n",
    "                if (\n",
    "                    self.board[r, c] == self.board[r + 1, c] == self.board[r + 2, c] == self.board[r + 3, c] != 0\n",
    "                ):\n",
    "                    return True\n",
    "\n",
    "        for r in range(self.board_rows - 3):\n",
    "            for c in range(self.board_cols - 3):\n",
    "                if (\n",
    "                    self.board[r, c] == self.board[r + 1, c + 1] == self.board[r + 2, c + 2] == self.board[r + 3, c + 3] != 0\n",
    "                ):\n",
    "                    return True\n",
    "\n",
    "        for r in range(3, self.board_rows):\n",
    "            for c in range(self.board_cols - 3):\n",
    "                if (\n",
    "                    self.board[r, c] == self.board[r - 1, c + 1] == self.board[r - 2, c + 2] == self.board[r - 3, c + 3] != 0\n",
    "                ):\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    def _check_draw(self):\n",
    "        return np.all(self.board != 0)\n",
    "\n",
    "    def render(self):\n",
    "        board_str = \"\"\n",
    "        board_str += \"-\" * (self.board_cols * 2 + 3) + \"\\n\"\n",
    "        for row in self.board:\n",
    "            board_str += \"| \"\n",
    "            for cell in row:\n",
    "                if cell == 1:\n",
    "                    board_str += \"x \"\n",
    "                elif cell == -1:\n",
    "                    board_str += \"o \"\n",
    "                else:\n",
    "                    board_str += \"  \"\n",
    "            board_str += \"|\\n\"\n",
    "        board_str += \"-\" * (self.board_cols * 2 + 3)\n",
    "        print(board_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a23d6032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:12:39.430603Z",
     "iopub.status.busy": "2025-04-09T23:12:39.430255Z",
     "iopub.status.idle": "2025-04-09T23:13:51.789621Z",
     "shell.execute_reply": "2025-04-09T23:13:51.788454Z"
    },
    "papermill": {
     "duration": 72.366842,
     "end_time": "2025-04-09T23:13:51.791723",
     "exception": false,
     "start_time": "2025-04-09T23:12:39.424881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    agent_dir = \"/kaggle/input/connect-4-agents/\"\n",
    "    agent_files = [f for f in os.listdir(agent_dir)]\n",
    "    agent_paths = [os.path.join(agent_dir, f) for f in agent_files]\n",
    "    agent_paths = zip_directories(agent_paths, \"/kaggle/working/opponents\")\n",
    "except:\n",
    "    agent_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93823b0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:13:51.802429Z",
     "iopub.status.busy": "2025-04-09T23:13:51.802047Z",
     "iopub.status.idle": "2025-04-09T23:14:02.082344Z",
     "shell.execute_reply": "2025-04-09T23:14:02.081324Z"
    },
    "papermill": {
     "duration": 10.287586,
     "end_time": "2025-04-09T23:14:02.084249",
     "exception": false,
     "start_time": "2025-04-09T23:13:51.796663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    checkpoint_dir = \"/kaggle/input/connect-4-checkpoints/\"\n",
    "    checkpoint_files = [f for f in os.listdir(checkpoint_dir)]\n",
    "    checkpoint_paths = [os.path.join(checkpoint_dir, f) for f in checkpoint_files]\n",
    "    zip_directories(checkpoint_paths, \"/kaggle/working/\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c91aa214",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-04-09T23:14:02.094894Z",
     "iopub.status.busy": "2025-04-09T23:14:02.094564Z",
     "iopub.status.idle": "2025-04-09T23:14:02.116149Z",
     "shell.execute_reply": "2025-04-09T23:14:02.115235Z"
    },
    "papermill": {
     "duration": 0.028759,
     "end_time": "2025-04-09T23:14:02.117954",
     "exception": false,
     "start_time": "2025-04-09T23:14:02.089195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Connect4TrainingEnv(gym.Wrapper):\n",
    "    def __init__(self, env, opponents):\n",
    "        super().__init__(env)\n",
    "        self.player_move = 0\n",
    "        self.opponents = opponents\n",
    "        self.current_opponent = opponents[0]\n",
    "        self.env = env\n",
    "        self.solver = Connect4Solver()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.player_move = 0\n",
    "        self.current_opponent = random.choice(self.opponents)\n",
    "        if type(self.current_opponent) == float:\n",
    "            self.current_opponent = random.uniform(0, self.current_opponent)\n",
    "        obs, info = self.env.reset(seed, options)\n",
    "        num_opening_moves = random.randint(0, 5)\n",
    "        while num_opening_moves:\n",
    "            opponent_action = self._get_valid_opp_move(obs, 0.5)\n",
    "            obs, *_ = self.env.step(opponent_action)\n",
    "            num_opening_moves -= 1\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        if self.player_move >= self.env.board_rows * self.env.board_cols / 1.5:\n",
    "            return self.env._get_observation(), 0, False, True, {}\n",
    "        old_turns = self.env.turns\n",
    "        observation, reward, done, truncated, info = self.env.step(action)\n",
    "        self.player_move += 1\n",
    "        if self.env.turns > old_turns and not done and not truncated:\n",
    "            opponent_action = self._get_valid_opp_move(observation)\n",
    "            observation, opp_reward, done, truncated, info = self.env.step(opponent_action)\n",
    "            reward -= opp_reward\n",
    "        return observation, reward, done, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"..... MOVE {self.player_move} .....\")\n",
    "        self.env.render()\n",
    "        \n",
    "    def update_opponents(self, model, replace_fraction = 0.5):\n",
    "        num_opps = len(self.opponents)\n",
    "        update_idxs = random.sample(range(num_opps), math.ceil(num_opps * replace_fraction))\n",
    "        for i in update_idxs:\n",
    "            self.opponents[i].set_parameters(model.get_parameters())\n",
    "    \n",
    "    def _get_valid_opp_move(self, observation, random_freq = 0.1):\n",
    "        valid_moves = self.env.get_valid_moves()\n",
    "        if type(self.current_opponent) == float:\n",
    "            opponent_action = self.solver.get_solver_move(self.env.move_history_str, temperature = self.current_opponent)\n",
    "        else:\n",
    "            opponent_action, _ = self.current_opponent.predict(observation, deterministic=False)\n",
    "        if opponent_action not in valid_moves or random.random() < random_freq:\n",
    "            opponent_action = random.choice(valid_moves)\n",
    "        return opponent_action\n",
    "\n",
    "class OpponentUpdateCallback(BaseCallback):\n",
    "    def __init__(self, self_play_env, verbose: int = 0):\n",
    "        super().__init__(verbose)\n",
    "        self.self_play_env = self_play_env\n",
    "\n",
    "    def _on_rollout_start(self) -> None:\n",
    "        self.self_play_env.update_opponents(self.model, 0.4)\n",
    "        pass\n",
    "    def _on_rollout_end(self) -> None:\n",
    "        self.self_play_env.update_opponents(self.model, 0.8)\n",
    "        pass\n",
    "        \n",
    "    def _on_training_start(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        return True\n",
    "\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        pass\n",
    "    \n",
    "\n",
    "def train_agent(agent_name, num_iterations, working_dir, opponents_dir=None, num_solver_opponents=0, solver_max_temp=0.5, rollout_len = 2**14):\n",
    "    policy_kwargs = dict(\n",
    "        net_arch = [2**13, 2**8, 2**9]\n",
    "    )\n",
    "    opponent_pool_size = 5 \n",
    "\n",
    "    selfplay = False\n",
    "    try:\n",
    "        opponents = []\n",
    "        opponent_paths = [f for f in os.listdir(opponents_dir) if f.endswith(\".zip\")]\n",
    "        opponent_paths = [os.path.join(opponents_dir, f) for f in opponent_paths]\n",
    "        for opponent_path in opponent_paths:\n",
    "            opponents.append(PPO.load(opponent_path))\n",
    "        print(f\"training against opponents: {opponent_paths}\")\n",
    "        num_solver_opponents = math.ceil(num_solver_opponents * len(opponent_paths))\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading opponents: {e}\")\n",
    "\n",
    "    if num_solver_opponents > 0:\n",
    "        opponents += num_solver_opponents * [solver_max_temp]\n",
    "        print(f\"training against solver\")\n",
    "    if not opponents:\n",
    "        print(f\"training using selfplay\")\n",
    "        selfplay = True\n",
    "        opponents = [PPO(\"MlpPolicy\", ConnectFourEnv(), policy_kwargs=policy_kwargs, verbose=0) for _ in range(opponent_pool_size)]\n",
    "\n",
    "    training_env = Connect4TrainingEnv(ConnectFourEnv(), opponents)\n",
    "\n",
    "    # Check for existing checkpoints\n",
    "    checkpoint_prefix = f\"checkpoints_{agent_name}\"\n",
    "    try:\n",
    "        checkpoint_dir = f\"{working_dir}\"\n",
    "        checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith(checkpoint_prefix) and f.endswith(\".zip\")]\n",
    "        checkpoint_paths = [os.path.join(checkpoint_dir, f) for f in checkpoint_files]\n",
    "        latest_checkpoint = max(checkpoint_paths, key=os.path.getmtime)\n",
    "        print(f\"Loading checkpoint: {latest_checkpoint}\")\n",
    "        model = PPO.load(latest_checkpoint, env=training_env, policy_kwargs=policy_kwargs)\n",
    "        total_timesteps = model.num_timesteps\n",
    "        print(f\"Checkpoint loaded. Timesteps: {total_timesteps}\")\n",
    "    except Exception as e:\n",
    "        print(f\"No checkpoint loaded {e}. Starting from scratch.\")\n",
    "        model = PPO(\"MlpPolicy\", training_env, policy_kwargs=policy_kwargs, verbose=1, n_steps=rollout_len)\n",
    "\n",
    "    print(model.policy)\n",
    "    checkpoint_callback = CheckpointCallback(save_freq=rollout_len * 2, save_path=f\"{working_dir}\", name_prefix=checkpoint_prefix)\n",
    "    opponent_update_callback = OpponentUpdateCallback(training_env)\n",
    "\n",
    "    callbacks = [checkpoint_callback]\n",
    "    if selfplay:\n",
    "        training_env.update_opponents(model, 1)\n",
    "        callbacks += [opponent_update_callback]\n",
    "    \n",
    "    model.learn(total_timesteps=rollout_len * num_iterations, callback=callbacks, reset_num_timesteps=False)\n",
    "\n",
    "    model.save(f\"{working_dir}/models/{agent_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd78f4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T23:14:02.128293Z",
     "iopub.status.busy": "2025-04-09T23:14:02.127868Z",
     "iopub.status.idle": "2025-04-10T10:29:46.721428Z",
     "shell.execute_reply": "2025-04-10T10:29:46.719534Z"
    },
    "papermill": {
     "duration": 40544.601682,
     "end_time": "2025-04-10T10:29:46.724276",
     "exception": false,
     "start_time": "2025-04-09T23:14:02.122594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:437: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  th_object = th.load(file_content, map_location=device)\n",
      "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:437: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  th_object = th.load(file_content, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training against opponents: ['/kaggle/working/opponents/opponent_007d.zip', '/kaggle/working/opponents/opponent_007b.zip', '/kaggle/working/opponents/opponent_008d.zip', '/kaggle/working/opponents/opponent_007e.zip', '/kaggle/working/opponents/opponent_008c.zip', '/kaggle/working/opponents/opponent_008e.zip', '/kaggle/working/opponents/opponent_007a.zip', '/kaggle/working/opponents/opponent_008a.zip', '/kaggle/working/opponents/opponent_008b.zip', '/kaggle/working/opponents/agent_000c.zip', '/kaggle/working/opponents/agent_000a.zip', '/kaggle/working/opponents/agent_000d.zip', '/kaggle/working/opponents/opponent_007c.zip', '/kaggle/working/opponents/agent_000b.zip']\n",
      "training against solver\n",
      "Loading checkpoint: /kaggle/working/checkpoints_b.zip\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Checkpoint loaded. Timesteps: 41418752\n",
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=512, out_features=7, bias=True)\n",
      "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.3     |\n",
      "|    ep_rew_mean     | 3.5      |\n",
      "| time/              |          |\n",
      "|    fps             | 152      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 430      |\n",
      "|    total_timesteps | 41484288 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.3        |\n",
      "|    ep_rew_mean          | 22.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1466        |\n",
      "|    total_timesteps      | 41549824    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023490453 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | -0.021      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 4.13e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.6        |\n",
      "|    ep_rew_mean          | 25.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2477        |\n",
      "|    total_timesteps      | 41615360    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023587517 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.124       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21e+03    |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0213     |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.3        |\n",
      "|    ep_rew_mean          | 16.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3513        |\n",
      "|    total_timesteps      | 41680896    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024373926 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.285      |\n",
      "|    explained_variance   | 0.165       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 3.52e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:278: UserWarning: Path '/kaggle/working/models' does not exist. Will create it.\n",
      "  warnings.warn(f\"Path '{path.parent}' does not exist. Will create it.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading opponents: expected str, bytes or os.PathLike object, not NoneType\n",
      "training using selfplay\n",
      "Loading checkpoint: /kaggle/working/checkpoints_b_41680896_steps.zip\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Checkpoint loaded. Timesteps: 41680896\n",
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=512, out_features=7, bias=True)\n",
      "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 12.9     |\n",
      "|    ep_rew_mean     | 42.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 190      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 343      |\n",
      "|    total_timesteps | 41746432 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.4        |\n",
      "|    ep_rew_mean          | 26.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 102         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1283        |\n",
      "|    total_timesteps      | 41811968    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035904326 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.275      |\n",
      "|    explained_variance   | 0.07        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | 28.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 88          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2218        |\n",
      "|    total_timesteps      | 41877504    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030373551 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.8        |\n",
      "|    ep_rew_mean          | 25.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3146        |\n",
      "|    total_timesteps      | 41943040    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029003192 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 1070        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | 30.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 4074        |\n",
      "|    total_timesteps      | 42008576    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029710744 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.271      |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.7        |\n",
      "|    ep_rew_mean          | 44.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4983        |\n",
      "|    total_timesteps      | 42074112    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029249953 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.262      |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+03    |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.8        |\n",
      "|    ep_rew_mean          | 35.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 5893        |\n",
      "|    total_timesteps      | 42139648    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028491871 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.264      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.3        |\n",
      "|    ep_rew_mean          | 35.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 6809        |\n",
      "|    total_timesteps      | 42205184    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030117914 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.256      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.5        |\n",
      "|    ep_rew_mean          | 33.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 76          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 7715        |\n",
      "|    total_timesteps      | 42270720    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030044459 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.254      |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.74e+03    |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 2.75e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.4       |\n",
      "|    ep_rew_mean          | 37.9       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 76         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 8609       |\n",
      "|    total_timesteps      | 42336256   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03270629 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.254     |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 749        |\n",
      "|    n_updates            | 1130       |\n",
      "|    policy_gradient_loss | -0.0174    |\n",
      "|    value_loss           | 2.68e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.2        |\n",
      "|    ep_rew_mean          | 38.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 9502        |\n",
      "|    total_timesteps      | 42401792    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030817457 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 933         |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.2        |\n",
      "|    ep_rew_mean          | 35.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 10391       |\n",
      "|    total_timesteps      | 42467328    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031798325 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.3        |\n",
      "|    ep_rew_mean          | 48.6        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 11288       |\n",
      "|    total_timesteps      | 42532864    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034501158 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.243      |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.7        |\n",
      "|    ep_rew_mean          | 19.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 12184       |\n",
      "|    total_timesteps      | 42598400    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032523636 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.238      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.1        |\n",
      "|    ep_rew_mean          | 28          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 75          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 13065       |\n",
      "|    total_timesteps      | 42663936    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031817466 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.236      |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "training against opponents: ['/kaggle/working/opponents/opponent_007d.zip', '/kaggle/working/opponents/opponent_007b.zip', '/kaggle/working/opponents/opponent_008d.zip', '/kaggle/working/opponents/opponent_007e.zip', '/kaggle/working/opponents/opponent_008c.zip', '/kaggle/working/opponents/opponent_008e.zip', '/kaggle/working/opponents/opponent_007a.zip', '/kaggle/working/opponents/opponent_008a.zip', '/kaggle/working/opponents/opponent_008b.zip', '/kaggle/working/opponents/agent_000c.zip', '/kaggle/working/opponents/agent_000a.zip', '/kaggle/working/opponents/agent_000d.zip', '/kaggle/working/opponents/opponent_007c.zip', '/kaggle/working/opponents/agent_000b.zip']\n",
      "training against solver\n",
      "Loading checkpoint: /kaggle/working/checkpoints_b_42598400_steps.zip\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Checkpoint loaded. Timesteps: 42598400\n",
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=512, out_features=7, bias=True)\n",
      "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.6     |\n",
      "|    ep_rew_mean     | -11.3    |\n",
      "| time/              |          |\n",
      "|    fps             | 132      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 495      |\n",
      "|    total_timesteps | 42663936 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11          |\n",
      "|    ep_rew_mean          | 10.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 82          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1581        |\n",
      "|    total_timesteps      | 42729472    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025621582 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.292      |\n",
      "|    explained_variance   | -0.0091     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 4.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.6        |\n",
      "|    ep_rew_mean          | 2.36        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 74          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2651        |\n",
      "|    total_timesteps      | 42795008    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023827873 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.289      |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.6e+03     |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 4.28e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 10.8        |\n",
      "|    ep_rew_mean          | -7.85       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 70          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3721        |\n",
      "|    total_timesteps      | 42860544    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023339473 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.287      |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09e+03    |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 4.53e+03    |\n",
      "-----------------------------------------\n",
      "Error loading opponents: expected str, bytes or os.PathLike object, not NoneType\n",
      "training using selfplay\n",
      "Loading checkpoint: /kaggle/working/checkpoints_b_42860544_steps.zip\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Checkpoint loaded. Timesteps: 42860544\n",
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=512, out_features=7, bias=True)\n",
      "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.6     |\n",
      "|    ep_rew_mean     | 42.3     |\n",
      "| time/              |          |\n",
      "|    fps             | 213      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 306      |\n",
      "|    total_timesteps | 42926080 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.6        |\n",
      "|    ep_rew_mean          | 27.5        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 110         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1185        |\n",
      "|    total_timesteps      | 42991616    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031117762 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.249      |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.7        |\n",
      "|    ep_rew_mean          | 41.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 95          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2062        |\n",
      "|    total_timesteps      | 43057152    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031478286 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.179       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.4        |\n",
      "|    ep_rew_mean          | 32.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 89          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2944        |\n",
      "|    total_timesteps      | 43122688    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035424158 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.258      |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 12.2       |\n",
      "|    ep_rew_mean          | 49         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 85         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 3832       |\n",
      "|    total_timesteps      | 43188224   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03383702 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.253     |\n",
      "|    explained_variance   | 0.232      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.47e+03   |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | -0.0173    |\n",
      "|    value_loss           | 2.71e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.3        |\n",
      "|    ep_rew_mean          | 51          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 83          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4715        |\n",
      "|    total_timesteps      | 43253760    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029092569 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.25       |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 1250        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 11.9      |\n",
      "|    ep_rew_mean          | 36        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 81        |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 5609      |\n",
      "|    total_timesteps      | 43319296  |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0315842 |\n",
      "|    clip_fraction        | 0.137     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.254    |\n",
      "|    explained_variance   | 0.26      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 703       |\n",
      "|    n_updates            | 1260      |\n",
      "|    policy_gradient_loss | -0.0165   |\n",
      "|    value_loss           | 2.69e+03  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | 45.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 80          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 6503        |\n",
      "|    total_timesteps      | 43384832    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032150477 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.253      |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 2.72e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | 48          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 79          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 7398        |\n",
      "|    total_timesteps      | 43450368    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030812774 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.252      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 2.8e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.6       |\n",
      "|    ep_rew_mean          | 39.7       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 79         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 8289       |\n",
      "|    total_timesteps      | 43515904   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03533929 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.246     |\n",
      "|    explained_variance   | 0.287      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.2e+03    |\n",
      "|    n_updates            | 1290       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 2.63e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.4        |\n",
      "|    ep_rew_mean          | 31.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 9178        |\n",
      "|    total_timesteps      | 43581440    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032480564 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.246      |\n",
      "|    explained_variance   | 0.305       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.22e+03    |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.1        |\n",
      "|    ep_rew_mean          | 33.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 78          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 10066       |\n",
      "|    total_timesteps      | 43646976    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031851023 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 1310        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11          |\n",
      "|    ep_rew_mean          | 44.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 10955       |\n",
      "|    total_timesteps      | 43712512    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034213822 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.24       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.6       |\n",
      "|    ep_rew_mean          | 40.5       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 77         |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 11850      |\n",
      "|    total_timesteps      | 43778048   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03218715 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.245     |\n",
      "|    explained_variance   | 0.262      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 969        |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 2.73e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 11.3        |\n",
      "|    ep_rew_mean          | 25.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 77          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 12739       |\n",
      "|    total_timesteps      | 43843584    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034149904 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.246      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 2.66e+03    |\n",
      "-----------------------------------------\n",
      "Error loading opponents: expected str, bytes or os.PathLike object, not NoneType\n",
      "training against solver\n",
      "Loading checkpoint: /kaggle/working/checkpoints_b_43778048_steps.zip\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Checkpoint loaded. Timesteps: 43778048\n",
      "ActorCriticPolicy(\n",
      "  (features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (pi_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (vf_features_extractor): FlattenExtractor(\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (mlp_extractor): MlpExtractor(\n",
      "    (policy_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "    (value_net): Sequential(\n",
      "      (0): Linear(in_features=84, out_features=8192, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=8192, out_features=256, bias=True)\n",
      "      (3): Tanh()\n",
      "      (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (5): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (action_net): Linear(in_features=512, out_features=7, bias=True)\n",
      "  (value_net): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.5     |\n",
      "|    ep_rew_mean     | -48.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 98       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 667      |\n",
      "|    total_timesteps | 43843584 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12          |\n",
      "|    ep_rew_mean          | -49.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 67          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1941        |\n",
      "|    total_timesteps      | 43909120    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029090459 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.306      |\n",
      "|    explained_variance   | -0.0062     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.06e+03    |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 4.38e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 11.7       |\n",
      "|    ep_rew_mean          | -41.8      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 60         |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 3225       |\n",
      "|    total_timesteps      | 43974656   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02617297 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.3       |\n",
      "|    explained_variance   | 0.121      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.2e+03    |\n",
      "|    n_updates            | 1350       |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    value_loss           | 4.77e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 12.2        |\n",
      "|    ep_rew_mean          | -38.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 57          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 4532        |\n",
      "|    total_timesteps      | 44040192    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027238704 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.298      |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.51e+03    |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 4.58e+03    |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent_name = \"b\"\n",
    "\n",
    "train_agent(agent_name, 4, \"/kaggle/working/\", \"/kaggle/working/opponents/\", num_solver_opponents = 0.4, rollout_len = 2 ** 16)\n",
    "train_agent(agent_name, 15, \"/kaggle/working/\", rollout_len = 2 ** 16)\n",
    "train_agent(agent_name, 4, \"/kaggle/working/\", \"/kaggle/working/opponents/\", num_solver_opponents = 1, rollout_len = 2 ** 16)\n",
    "train_agent(agent_name, 15, \"/kaggle/working/\", rollout_len = 2 ** 16)\n",
    "train_agent(agent_name, 4, \"/kaggle/working/\", num_solver_opponents = 1, rollout_len = 2 ** 16)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7085602,
     "sourceId": 11345222,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6884852,
     "sourceId": 11346087,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40677.816987,
   "end_time": "2025-04-10T10:29:50.786406",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-09T23:11:52.969419",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
