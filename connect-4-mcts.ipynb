{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11403853,"sourceType":"datasetVersion","datasetId":7085602}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import gymnasium as gym\nfrom gymnasium import spaces\nimport numpy as np\nimport itertools\n\nfrom stable_baselines3 import PPO\nfrom stable_baselines3.common.env_util import make_vec_env\nfrom stable_baselines3.common.utils import set_random_seed\nfrom stable_baselines3.common.callbacks import BaseCallback, CheckpointCallback\nimport copy\nimport random, math\nimport os\nimport torch as th\nfrom torch import nn\nfrom stable_baselines3.common.torch_layers import BaseFeaturesExtractor","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-04-14T16:21:47.330695Z","iopub.execute_input":"2025-04-14T16:21:47.331123Z","iopub.status.idle":"2025-04-14T16:22:09.639631Z","shell.execute_reply.started":"2025-04-14T16:21:47.331090Z","shell.execute_reply":"2025-04-14T16:22:09.638583Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/tensorflow/lite/python/util.py:55: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs; see https://jax.readthedocs.io/en/latest/aot.html. For example, replace xla_computation(f)(*xs) with jit(f).lower(*xs).compiler_ir('hlo'). See CHANGELOG.md for 0.4.30 for more examples.\n  from jax import xla_computation as _xla_computation\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import math\nimport numpy as np\nimport pexpect\nimport ctypes\n\nclass Connect4Solver:\n    !pip install stable_baselines3\n    !git clone https://github.com/TonyCongqianWang/connect4_solver_fork.git && cd connect4_solver_fork && make\n    !curl -L https://github.com/PascalPons/connect4/releases/download/book/7x6.book --output 7x6.book\n    solver_path='./connect4_solver_fork/c4solver_c_interface.so'\n    solver_lib = ctypes.CDLL(solver_path)\n            \n    solver_lib.solver_init.argtypes = [ctypes.c_char_p]\n    solver_lib.solver_init.restype = ctypes.POINTER(ctypes.c_void_p)\n    \n    solver_lib.solver_delete.argtypes = [ctypes.POINTER(ctypes.c_void_p)]\n    solver_lib.solver_delete.restype = None\n    \n    solver_lib.solver_solve.argtypes = [ctypes.POINTER(ctypes.c_void_p), ctypes.c_char_p, ctypes.c_bool, ctypes.c_bool, ctypes.c_char_p, ctypes.c_size_t]\n    solver_lib.solver_solve.restype = ctypes.c_char_p\n    def __init__(self):\n        \"\"\"\n        Initializes the Connect4Solver with the path to the solver executable.\n\n        Args:\n            solver_path (str): Path to the Connect4 solver executable.\n        \"\"\"\n        self.MAX_SCORE = 24\n        self.handle = Connect4Solver.solver_lib.solver_init(None)\n        self.result_buffer = ctypes.create_string_buffer(256)\n\n    def __del__(self):\n        \"\"\"\n        Destructor that sends EOF to the solver process.\n        \"\"\"\n        if hasattr(self, 'child') and self.child is not None:\n            try:\n                self.child.sendeof()\n            except:\n                pass\n\n    def _process_output(self, prompt_str, answer_str):\n        \"\"\"\n        Processes the output from the solver.\n\n        Args:\n            prompt_str (str): The prompt string.\n            answer_str (str): The answer string.\n\n        Returns:\n            list: List of floats representing the processed output.\n        \"\"\"\n        if answer_str.startswith(prompt_str):\n            answer_str = answer_str[len(prompt_str):].strip()\n            \n        answer_list = [float(x) for x in answer_str.split()]\n        return answer_list\n\n    def _softmax(self, x, temperature=1.0):\n        \"\"\"\n        Calculates a modified softmax that approaches argmax for small temperatures.\n\n        For very small temperatures, indices with the maximum value will receive\n        equal probability, and the rest will receive 0.\n\n        Args:\n            x (list): List of values.\n            temperature (float): Temperature parameter for softmax.\n\n        Returns:\n            list: List of probabilities.\n        \"\"\"\n        if temperature <= 1e-5:  # Consider a very small temperature as argmax\n            max_val = max(x)\n            max_indices = [i for i, val in enumerate(x) if val == max_val]\n            probabilities = [0.0] * len(x)\n            prob = 1.0 / len(max_indices)\n            for i in max_indices:\n                probabilities[i] = prob\n            return probabilities\n        else:\n            e_x = []\n            for i in x:\n                # Clipping to prevent overflow for large positive values\n                exponent = i / temperature\n                if exponent > 100:  # Or a suitable large value\n                    e_x.append(float('inf'))\n                elif exponent < -100:\n                    e_x.append(0.0)\n                else:\n                    e_x.append(math.exp(exponent))\n\n            sum_e_x = sum(e_x)\n            if sum_e_x == 0:\n                return ([1.0] * len(x)) / len(x)\n            return [e / sum_e_x for e in e_x]\n\n    def _transform_and_softmax(self, data, score_offset, temperature):\n        \"\"\"\n        Transforms and calculates the softmax of the data.\n\n        Args:\n            data (list): List of data values.\n            temperature (float): Temperature parameter for softmax.\n\n        Returns:\n            list: List of softmax probabilities.\n        \"\"\"\n        transformed_data = []\n        for x in data:\n            sign = 1 if x > 0 else -1 if x < 0 else 0\n            if x > -1000:\n                transformed_x = sign * ((abs(x) + score_offset) / self.MAX_SCORE * 5)\n            else:\n                transformed_x = -1000\n            transformed_data.append(transformed_x)\n        #print(transformed_data)\n        return self._softmax(transformed_data, temperature)\n\n    def _random_index(self, softmax_probs):\n        \"\"\"\n        Selects a random index based on softmax probabilities.\n\n        Args:\n            softmax_probs (list): List of softmax probabilities.\n\n        Returns:\n            int: Selected index.\n        \"\"\"\n        selected_index = np.random.choice(len(softmax_probs), p=softmax_probs)\n        return selected_index\n\n    def get_solver_move(self, move_str, temperature=1.0):\n        \"\"\"\n        Gets a move from the solver.\n\n        Args:\n            move_str (str): Move string to send to the solver.\n            temperature (float): Temperature parameter for softmax.\n\n        Returns:\n            int: Selected move index.\n        \"\"\"\n        try:\n            result = Connect4Solver.solver_lib.solver_solve(self.handle, move_str.encode(\"utf-8\"), False, True, self.result_buffer, 256)\n            answer = result.decode()\n            score_offset = math.floor(len(move_str) / 2)\n            probas = self._transform_and_softmax(self._process_output(move_str, answer), score_offset, temperature)\n            #print(f\"{answer}\")\n            #print(probas)\n            return self._random_index(probas)\n        except Exception as e:\n            print(f\"{e}\")\n            print(f\"{answer}\")\n        return 0","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-04-14T16:22:09.641007Z","iopub.execute_input":"2025-04-14T16:22:09.641799Z","iopub.status.idle":"2025-04-14T16:22:23.326932Z","shell.execute_reply.started":"2025-04-14T16:22:09.641756Z","shell.execute_reply":"2025-04-14T16:22:23.325634Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  and should_run_async(code)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.10/dist-packages (2.1.0)\nRequirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (0.29.0)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (1.26.4)\nRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.5.1+cu121)\nRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.1.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.5)\nRequirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.12.2)\nRequirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (0.0.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->stable_baselines3) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.17.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable_baselines3) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (11.0.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->stable_baselines3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->stable_baselines3) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->stable_baselines3) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->stable_baselines3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->stable_baselines3) (2024.2.0)\nCloning into 'connect4_solver_fork'...\nremote: Enumerating objects: 149, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (14/14), done.\u001b[K\nremote: Total 149 (delta 17), reused 13 (delta 13), pack-reused 122 (from 2)\u001b[K\nReceiving objects: 100% (149/149), 67.77 KiB | 2.42 MiB/s, done.\nResolving deltas: 100% (87/87), done.\ng++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC -MM Solver.cpp > ./.depend\ng++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC   -c -o Solver.o Solver.cpp\ng++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC   -c -o main.o main.cpp\ng++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC  -o c4solver main.o Solver.o \ng++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC   -c -o generator.o generator.cpp\ng++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC  -o generator generator.o \ng++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC   -c -o solver_c_interface.o solver_c_interface.cpp\ng++ --std=c++11 -W -Wall -O3 -DNDEBUG -fPIC  -shared -o c4solver_c_interface.so solver_c_interface.o Solver.o \n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n100 32.0M  100 32.0M    0     0  24.8M      0  0:00:01  0:00:01 --:--:-- 45.6M\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import zipfile\n\ndef zip_directories(directory_paths, working_dir):\n    \"\"\"\n    Zips the given directories into their parent directory.\n\n    Args:\n        directory_paths (list): A list of paths to directories.\n\n    Returns:\n        list: A list of paths to the created zip files.\n    \"\"\"\n    os.makedirs(working_dir, exist_ok=True)\n    \n    zip_file_paths = []\n    for dir_path in directory_paths:\n        if not os.path.isdir(dir_path):\n            print(f\"Warning: {dir_path} is not a directory. Skipping.\")\n            continue\n\n        parent_dir = working_dir\n        dir_name = os.path.basename(dir_path)\n        zip_file_path = os.path.join(parent_dir, f\"{dir_name}.zip\")\n\n        try:\n            with zipfile.ZipFile(zip_file_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n                for root, _, files in os.walk(dir_path):\n                    for file in files:\n                        file_path = os.path.join(root, file)\n                        relative_path = os.path.relpath(file_path, dir_path)\n                        zipf.write(file_path, relative_path)\n            zip_file_paths.append(zip_file_path)\n        except Exception as e:\n            print(f\"Error zipping {dir_path}: {e}\")\n\n    return zip_file_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T16:22:23.329159Z","iopub.execute_input":"2025-04-14T16:22:23.329510Z","iopub.status.idle":"2025-04-14T16:22:23.337163Z","shell.execute_reply.started":"2025-04-14T16:22:23.329476Z","shell.execute_reply":"2025-04-14T16:22:23.336087Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class ConnectFourEnv(gym.Env):\n    metadata = {\"render_modes\": [\"human\", \"ansi\", \"rgb_array\"], \"render_fps\": 1}\n    def __init__(self, render_mode=None, board_rows=6, board_cols=7):\n        super(ConnectFourEnv, self).__init__()\n        self.board_rows = board_rows\n        self.board_cols = board_cols\n        self.action_space = spaces.Discrete(self.board_cols)  # Columns to drop a piece\n        self.observation_space = spaces.Box(low=0, high=255, shape=(2, self.board_rows, self.board_cols), dtype=np.uint8)  # two binary matrices. one for each players stones\n        self.render_mode = render_mode\n        self.move_history = \"\"\n        \n        self.reset()\n\n    def reset(self, seed=None, options=None):\n        super().reset(seed=seed, options=options)\n        self.board = np.zeros((self.board_rows, self.board_cols), dtype=np.int8)\n        self.player = 1  # Player 1 starts\n        self.done = False\n        self.truncated = False\n        self.winner = None\n        self.turns = 0\n        self.move_history_str = \"\"\n        info = {}\n        return self._get_observation(), info\n\n    def step(self, action):\n        if self.done:\n            return self._get_observation(), 0, True, False, {}\n\n        if not self._is_valid_move(action):\n            return self._get_observation(), -50, False, False, {}\n\n        self._drop_piece(action)\n        self.move_history_str += str(action + 1)\n        self.turns += 1\n\n        if self._check_win():\n            self.done = True\n            self.winner = self.player\n            reward = 80 + 20 * (len(self.board.flatten()) - self.turns) / len(self.board.flatten())\n        elif self._check_draw():\n            self.done = True\n            reward = 0\n        else:\n            reward = 0\n        self.player *= -1  # Switch players\n        return  self._get_observation(), reward, self.done, False, {}\n\n    def get_valid_moves(self):\n        valid_moves = []\n        for col in range(self.board_cols):\n            if self._is_valid_move(col):\n                valid_moves.append(col)\n        return valid_moves\n\n    def _get_observation(self):\n        m, n = self.board.shape\n        player_perspective = self.board * self.player\n        new_array = np.zeros((2, m, n), dtype=np.uint8)\n        new_array[0, :, :] = 255 * (player_perspective == 1).astype(np.uint8)\n        new_array[1, :, :] = 255 * (player_perspective == -1).astype(np.uint8)\n        return new_array\n\n    def _is_valid_move(self, col):\n        return self.board[0, col] == 0\n\n    def _drop_piece(self, col):\n        for row in range(self.board_rows - 1, -1, -1):\n            if self.board[row, col] == 0:\n                self.board[row, col] = self.player\n                return\n\n    def _check_win(self):\n        # Check horizontal, vertical, and diagonal wins\n        for r in range(self.board_rows):\n            for c in range(self.board_cols - 3):\n                if (\n                    self.board[r, c] == self.board[r, c + 1] == self.board[r, c + 2] == self.board[r, c + 3] != 0\n                ):\n                    return True\n\n        for c in range(self.board_cols):\n            for r in range(self.board_rows - 3):\n                if (\n                    self.board[r, c] == self.board[r + 1, c] == self.board[r + 2, c] == self.board[r + 3, c] != 0\n                ):\n                    return True\n\n        for r in range(self.board_rows - 3):\n            for c in range(self.board_cols - 3):\n                if (\n                    self.board[r, c] == self.board[r + 1, c + 1] == self.board[r + 2, c + 2] == self.board[r + 3, c + 3] != 0\n                ):\n                    return True\n\n        for r in range(3, self.board_rows):\n            for c in range(self.board_cols - 3):\n                if (\n                    self.board[r, c] == self.board[r - 1, c + 1] == self.board[r - 2, c + 2] == self.board[r - 3, c + 3] != 0\n                ):\n                    return True\n        return False\n\n    def _check_draw(self):\n        return np.all(self.board != 0)\n\n    def render(self):\n        board_str = \"\"\n        board_str += \"-\" * (self.board_cols * 2 + 3) + \"\\n\"\n        for row in self.board:\n            board_str += \"| \"\n            for cell in row:\n                if cell == 1:\n                    board_str += \"x \"\n                elif cell == -1:\n                    board_str += \"o \"\n                else:\n                    board_str += \"  \"\n            board_str += \"|\\n\"\n        board_str += \"-\" * (self.board_cols * 2 + 3)\n        print(board_str)\n\n    def copy(self):\n        \"\"\"Creates a deep copy of the environment state.\"\"\"\n        new_env = ConnectFourEnv(render_mode=self.render_mode, board_rows=self.board_rows, board_cols=self.board_cols)\n        new_env.board = self.board.copy()\n        new_env.player = self.player\n        new_env.done = self.done\n        new_env.winner = self.winner\n        new_env.turns = self.turns\n        new_env.move_history_str = self.move_history_str\n        return new_env","metadata":{"trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-04-14T16:29:06.194867Z","iopub.execute_input":"2025-04-14T16:29:06.195342Z","iopub.status.idle":"2025-04-14T16:29:06.215448Z","shell.execute_reply.started":"2025-04-14T16:29:06.195309Z","shell.execute_reply":"2025-04-14T16:29:06.214241Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"try:\n    agent_dir = \"/kaggle/input/connect-4-agents/\"\n    agent_files = [f for f in os.listdir(agent_dir)]\n    agent_paths = [os.path.join(agent_dir, f) for f in agent_files]\n    agent_paths = zip_directories(agent_paths, \"/kaggle/working/agents\")\nexcept:\n    agent_paths = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T16:22:23.365295Z","iopub.execute_input":"2025-04-14T16:22:23.365701Z","iopub.status.idle":"2025-04-14T16:23:36.719246Z","shell.execute_reply.started":"2025-04-14T16:22:23.365674Z","shell.execute_reply":"2025-04-14T16:23:36.718208Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import numpy as np\nimport math\nimport random\nfrom collections import defaultdict\n\nimport numpy as np\nfrom stable_baselines3.common.policies import obs_as_tensor\n\ndef get_value_policy(model, state):\n    obs = obs_as_tensor(state.reshape(1,-1), model.policy.device)\n    dis = model.policy.get_distribution(obs)\n    probs = dis.distribution.probs\n    probs_np = probs.detach().numpy()[0]\n    value = model.policy.predict_values(obs)\n    value_np = value.detach().numpy()[0][0]\n    return value_np, probs_np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T16:23:36.721488Z","iopub.execute_input":"2025-04-14T16:23:36.721803Z","iopub.status.idle":"2025-04-14T16:23:36.728073Z","shell.execute_reply.started":"2025-04-14T16:23:36.721779Z","shell.execute_reply":"2025-04-14T16:23:36.726877Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import math\nimport numpy as np\nimport gymnasium as gym\nfrom gymnasium.spaces import Discrete\n\nclass Node:\n    def __init__(self, env, parent=None, action=None, prior_prob=0):\n        self.env = env\n        self.parent = parent\n        self.action = action\n        self.children = {}\n        self.visit_count = 0\n        self.total_value = 0\n        self.prior_prob = prior_prob\n        self.player = env.player\n        self.value = None\n        self.policy = None\n\n    def is_fully_expanded(self, legal_actions):\n        return len(self.children) == len(legal_actions)\n\n    def select_child(self, exploration_constant):\n        best_child = None\n        best_uct = -float('inf')\n        for action, child in self.children.items():\n            # Determine the value from the perspective of the current node (self)\n            value_from_current_perspective = child.total_value\n            if self.player != child.player:\n                # If the child represents the opponent's turn, negate the value\n                value_from_current_perspective = -child.total_value\n\n            average_value = value_from_current_perspective / (child.visit_count + 1e-6)\n\n            uct_value = (average_value +\n                         exploration_constant * child.prior_prob *\n                         math.sqrt(self.visit_count + 1e-6) / (child.visit_count + 1))\n\n            if uct_value > best_uct:\n                best_uct = uct_value\n                best_child = child\n        return best_child\n\n    def update(self, value):\n        self.visit_count += 1\n        self.total_value += value\n\n    def _get_observation(self, env):\n        observation = None\n        if hasattr(env, '_get_observation'): observation = env._get_observation()\n        else:\n            raise NotImplementedError(\"Warning: Environment does not have a '_get_observation' attribute.\")\n        return observation\n\n    def _apply_temperature_to_policy(self, policy, temperature=1.0):\n        policy = np.array(policy, dtype=float)  # Ensure it's a numpy array\n    \n        if temperature <= 0.1:  # Handle very low temperature for determinism\n            best_action_index = np.argmax(policy)\n            transformed_policy = np.zeros_like(policy)\n            transformed_policy[best_action_index] = 1.0\n            return transformed_policy\n        else:\n            # Raise probabilities to the power of 1/temperature\n            tempered_policy = np.power(policy, 1 / temperature)\n            # Normalize the tempered policy to get a probability distribution\n            transformed_policy = tempered_policy / np.sum(tempered_policy)\n            return transformed_policy\n    \n    def get_value_and_policy(self, agent, temperature):\n        if self.value is None or self.policy is None:\n            observation = self._get_observation(self.env)\n            value, policy = get_value_policy(agent, observation)\n            self.value = value\n            policy = self._apply_temperature_to_policy(policy, temperature)\n            self.policy = policy\n        return self.value, self.policy\n\nclass MCTS:\n    def __init__(self, agent, exploration_constant=1.0, num_simulations=1000, discount_factor=1.0, terminal_reward_multiplier=1.0, temperature=1.0):\n        self.agent = agent\n        self.exploration_constant = exploration_constant\n        self.num_simulations = num_simulations\n        self.discount_factor = discount_factor\n        self.terminal_reward_multiplier = terminal_reward_multiplier\n        self.root = None\n        self.temperature = temperature\n\n    def _get_action_index(self, action):\n        return action\n    \n    def _simulate(self, node):\n        current_node = node\n        env = current_node.env\n\n        # Selection\n        legal_actions = self._get_legal_actions(env)\n        while current_node.children and current_node.is_fully_expanded(legal_actions):\n            current_node = current_node.select_child(self.exploration_constant)\n            env = current_node.env\n            legal_actions = self._get_legal_actions(env)\n            if self._is_terminal_state(env):\n                reward = self._get_reward(env)\n                self._backpropagate(current_node, reward)\n                return reward\n\n        # Expansion\n        if not self._is_terminal_state(env) and not current_node.is_fully_expanded(legal_actions):\n            unvisited_actions = [a for a in legal_actions if a not in current_node.children]\n            if unvisited_actions:\n                _, policy = current_node.get_value_and_policy(self.agent, self.temperature)\n\n                best_unvisited_action = unvisited_actions[0]\n                highest_prior_prob = policy[0]\n\n                for action in unvisited_actions[1:]:\n                    action_index = self._get_action_index(action)\n                    prior_prob = policy[action_index] if len(policy) > action_index else 0\n                    if prior_prob > highest_prior_prob:\n                        highest_prior_prob = prior_prob\n                        best_unvisited_action = action\n\n                action = best_unvisited_action\n                next_env = env.copy()\n                observation, reward, terminated, truncated, info = next_env.step(action)\n                action_index = self._get_action_index(action)\n                prior_prob = policy[action_index] if len(policy) > action_index else 0\n\n                if terminated or truncated:\n                    reward = self._get_reward(next_env)\n                    new_node = Node(next_env, parent=current_node, action=action, prior_prob=0)\n                    current_node.children[action] = new_node\n                    self._backpropagate(new_node, reward)\n                    return reward\n                else:\n                    new_node = Node(next_env, parent=current_node, action=action, prior_prob=prior_prob)\n                    current_node.children[action] = new_node\n                    current_node = new_node\n        \n        leaf_node_value, _ = current_node.get_value_and_policy(self.agent, self.temperature)\n        self._backpropagate(current_node, leaf_node_value)\n        return leaf_node_value\n\n    def _get_reward(self, env):\n        if not self._is_terminal_state(env):\n            return 0\n        if hasattr(env, 'winner'):\n            if env.winner is None:\n                return 0\n            elif env.winner == env.player:\n                return 100 * self.terminal_reward_multiplier\n            elif env.winner == self._get_opponent(env.player):\n                return -100 * self.terminal_reward_multiplier\n        else:\n            raise NotImplementedError(\"Enviroment needs env.winner attribute.\")\n\n    def _backpropagate(self, node, value):\n        discount = 1.0\n        while node is not None:\n            node.update(value * discount)\n            value = -value\n            discount *= self.discount_factor\n            node = node.parent\n\n    def _get_legal_actions(self, env):\n        if hasattr(env, 'get_valid_moves'):\n            return env.get_valid_moves()\n        else:\n            raise NotImplementedError(\"Enviroment needs env.winner get_valid_moves.\")\n\n    def _is_terminal_state(self, env):\n        return env.done or env.truncated\n\n    def _get_opponent(self, player):\n        return -player\n\n    def search(self, initial_env, verbose=False):\n        self.root = Node(initial_env)\n        value, policy = self.root.get_value_and_policy(self.agent, self.temperature)\n        legal_actions = self._get_legal_actions(initial_env)\n\n        if self._is_terminal_state(self.root.env):\n            print(\"WARNING: root node is terminated state.\")\n        \n        if verbose:\n            print(f\"Root node value: {value}\")\n            print(f\"Root node policy: {policy}\")\n\n        for i, action in enumerate(legal_actions):\n            next_env = initial_env.copy()\n            obs, _, terminated, truncated, _ = next_env.step(action)\n            action_index = self._get_action_index(action)\n            prior_prob = policy[action_index] if len(policy) > action_index else 0\n            self.root.children[action] = Node(next_env, parent=self.root, action=action, prior_prob=prior_prob)\n\n        if verbose:\n            print(\"Run Simulations\")\n        for _ in range(self.num_simulations):\n            if verbose:\n                print(\".\",end=\"\")\n            self._simulate(self.root)\n        if verbose:\n            print(\"\\ndone\")\n        best_actions = []\n        max_visits = -1\n        for action, child in self.root.children.items():\n            if child.visit_count > max_visits:\n                max_visits = child.visit_count\n                best_actions = [action]\n            elif child.visit_count == max_visits:\n                best_actions.append(action)\n\n        if verbose:\n            print(\"Root state:\")\n            self.root.env.render()\n            cur_node = self.root\n            actions = []\n            while True:\n                print(f\"Node {actions}  Statistics:\")\n                value, policy = cur_node.get_value_and_policy(self.agent, self.temperature)\n                print(f\"Node value: {value}\")\n                print(f\"Node policy: {policy}\")\n                print(f\"  Visits: {cur_node.visit_count}, Total Value: {cur_node.total_value}\")\n                print(f\"Child Node Statistics:\")\n                best_child = None\n                max_child_visits = -1\n                best_action_in_path = None\n                for action in sorted(cur_node.children.keys()):\n                    child = cur_node.children[action]\n                    print(f\"  Action: {action}, Visits: {child.visit_count}, Total Value: {child.total_value} Avg Value: {child.total_value / (child.visit_count + 1e-6)}\")\n                    if child.visit_count > max_child_visits:\n                        max_child_visits = child.visit_count\n                        best_child = child\n                        best_action_in_path = action\n\n                if best_child and len(actions) < 3:\n                    actions.append(best_action_in_path)\n                    cur_node = best_child\n                else:\n                    break\n        return random.choice(best_actions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:17:41.369729Z","iopub.execute_input":"2025-04-14T19:17:41.370148Z","iopub.status.idle":"2025-04-14T19:17:41.398788Z","shell.execute_reply.started":"2025-04-14T19:17:41.370117Z","shell.execute_reply":"2025-04-14T19:17:41.397353Z"}},"outputs":[],"execution_count":158},{"cell_type":"code","source":"from collections import defaultdict\nimport pandas as pd\n\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\ndef get_best_agent_name(results_df):\n    \"\"\"Returns the name of the best agent (excluding solvers).\"\"\"\n    for index, row in results_df.iterrows():\n        if \"Solver\" not in row[\"Agent\"]:\n            return row[\"Agent\"]\n    return None  # Return None if no agent name without \"Solver\" is found.\n    \ndef evaluate_best_agent_mcts(best_agent, num_episodes=10):\n    \"\"\"Evaluates the best agent (based on Elo) against solvers using MCTS.\"\"\"\n    env = ConnectFourEnv()\n    solver = Connect4Solver()\n    solver_temps = [0.0, 0.1, 0.15, 0.2, 0.3, 0.5, 1.0]\n    \n    mcts = MCTS(best_agent, num_simulations=300, discount_factor=0.95, terminal_reward_multiplier=2.0, exploration_constant=200, temperature=3.0)\n    mcts_results = defaultdict(lambda: {\"wins_1st\": 0, \"draws_1st\": 0, \"loses_1st\": 0, \"wins_2nd\": 0, \"draws_2nd\": 0, \"loses_2nd\": 0})\n    \n    for solver_temp in solver_temps:\n        for episode in range(num_episodes):\n            obs, _ = env.reset()\n            done = False\n            agent_first = (episode % 2 == 0)\n            res_suffix = \"_1st\" if agent_first else \"_2nd\"\n            while not done:\n                if (env.player == 1 and agent_first) or (env.player == -1 and not agent_first):\n                    # Use MCTS to select the best move\n                    action = mcts.search(env)\n                else:\n                    action = solver.get_solver_move(env.move_history_str, solver_temp)\n\n                valid_moves = env.get_valid_moves()\n                if action not in valid_moves:\n                    action = random.choice(valid_moves)\n                obs, reward, done, truncated, _ = env.step(action)\n\n            if done or truncated:\n                print(f\"MCTS Episode {episode + 1} vs Solver_{solver_temp}: {agent_first=}\")\n                env.render()\n                if (env.winner == 1 and agent_first) or (env.winner == -1 and not agent_first):\n                    mcts_results[f\"Solver_{solver_temp}\"][f\"wins{res_suffix}\"] += 1\n                elif reward == 0:\n                    mcts_results[f\"Solver_{solver_temp}\"][f\"draws{res_suffix}\"] += 1\n                else:\n                    mcts_results[f\"Solver_{solver_temp}\"][f\"loses{res_suffix}\"] += 1\n            print(mcts_results)\n    env.close()\n\n    columns = [\"Opponent\", \"Wins_1st\", \"Draws_1st\", \"Loses_1st\", \"Wins_2nd\", \"Draws_2nd\", \"Loses_2nd\"]\n    data = []\n    for solver_temp, result in mcts_results.items():\n        data.append([solver_temp, result[\"wins_1st\"], result[\"draws_1st\"], result[\"loses_1st\"], result[\"wins_2nd\"], result[\"draws_2nd\"], result[\"loses_2nd\"]])\n\n    mcts_df = pd.DataFrame(data, columns=columns)\n    return mcts_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:18:34.943350Z","iopub.execute_input":"2025-04-14T19:18:34.943780Z","iopub.status.idle":"2025-04-14T19:18:34.955324Z","shell.execute_reply.started":"2025-04-14T19:18:34.943736Z","shell.execute_reply":"2025-04-14T19:18:34.954309Z"}},"outputs":[],"execution_count":160},{"cell_type":"code","source":"data = {\"Agent\": [\"004a.zip\"]}\ndf = pd.DataFrame(data)\nbest_agent_name = get_best_agent_name(df)\nif best_agent_name:\n    print(f\"The best agent is: {best_agent_name}\")\n    best_agent_path = next(path for path in agent_paths if best_agent_name in path)\n    best_agent = PPO.load(best_agent_path)\nelse:\n    print(\"No non-solver agents found.\")\n    best_agent = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T16:23:36.889938Z","iopub.execute_input":"2025-04-14T16:23:36.890321Z","iopub.status.idle":"2025-04-14T16:23:40.778827Z","shell.execute_reply.started":"2025-04-14T16:23:36.890293Z","shell.execute_reply":"2025-04-14T16:23:40.777486Z"}},"outputs":[{"name":"stdout","text":"The best agent is: 004a.zip\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:437: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  th_object = th.load(file_content, map_location=device)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"c4env = ConnectFourEnv()\nsolver = Connect4Solver()\nc4env.reset()\nc4env.step(3)\nc4env.step(3)\n\nc4env.step(3)\nc4env.step(3)\n\nc4env.step(3)\nc4env.step(4)\n\n#c4env.step(4)\n\nmcts = MCTS(best_agent, num_simulations=300, discount_factor=0.95, terminal_reward_multiplier=2.0, exploration_constant=200, temperature=3.0)\nobs = c4env._get_observation()\nget_value_policy(best_agent, obs)\nbest_action = mcts.search(c4env, verbose=True)\nprint(\"agent: \", best_agent.predict(obs, deterministic=True)[0])\nprint(\"mcts: \", best_action)\nprint(\"solver: \", solver.get_solver_move(c4env.move_history_str, temperature=0.0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:17:47.616628Z","iopub.execute_input":"2025-04-14T19:17:47.617048Z","iopub.status.idle":"2025-04-14T19:17:48.957438Z","shell.execute_reply.started":"2025-04-14T19:17:47.617018Z","shell.execute_reply":"2025-04-14T19:17:48.956340Z"}},"outputs":[{"name":"stdout","text":"Root node value: 14.955658912658691\nRoot node policy: [0.01014135 0.02156168 0.01708217 0.02036335 0.91672299 0.00674083\n 0.00738764]\nRun Simulations\n............................................................................................................................................................................................................................................................................................................\ndone\nRoot state:\n-----------------\n|               |\n|       x       |\n|       o       |\n|       x       |\n|       o       |\n|       x o     |\n-----------------\nNode []  Statistics:\nNode value: 14.955658912658691\nNode policy: [0.01014135 0.02156168 0.01708217 0.02036335 0.91672299 0.00674083\n 0.00738764]\n  Visits: 300, Total Value: 3394.411633684646\nChild Node Statistics:\n  Action: 0, Visits: 1, Total Value: 4.3011133670806885 Avg Value: 4.301109065971623\n  Action: 1, Visits: 3, Total Value: -7.604683971405029 Avg Value: -2.5348938121704054\n  Action: 2, Visits: 2, Total Value: 19.190242624282835 Avg Value: 9.59511651458316\n  Action: 3, Visits: 2, Total Value: 20.544169473648072 Avg Value: 10.272079600784235\n  Action: 4, Visits: 290, Total Value: -3647.994121699593 Avg Value: -12.579290031449322\n  Action: 5, Visits: 0, Total Value: 0 Avg Value: 0.0\n  Action: 6, Visits: 2, Total Value: 38.49840264320373 Avg Value: 19.249191697006015\nNode [4]  Statistics:\nNode value: -15.332045555114746\nNode policy: [0.02683382 0.03846678 0.007942   0.00893258 0.89124133 0.00361234\n 0.02297115]\n  Visits: 290, Total Value: -3647.994121699593\nChild Node Statistics:\n  Action: 0, Visits: 2, Total Value: 96.71792621612549 Avg Value: 48.358938928593275\n  Action: 1, Visits: 3, Total Value: 138.67554931640623 Avg Value: 46.22516769707951\n  Action: 2, Visits: 1, Total Value: 46.66632843017578 Avg Value: 46.66628176389402\n  Action: 3, Visits: 2, Total Value: 81.0379690170288 Avg Value: 40.51896424903227\n  Action: 4, Visits: 278, Total Value: 3344.699956457511 Avg Value: 12.031294764123079\n  Action: 5, Visits: 2, Total Value: 33.914153480529784 Avg Value: 16.95706826173076\n  Action: 6, Visits: 2, Total Value: 98.281929397583 Avg Value: 49.14094012832143\nNode [4, 4]  Statistics:\nNode value: 18.049522399902344\nNode policy: [1.61766160e-03 4.59631562e-03 3.73885799e-04 5.60401992e-03\n 9.67431307e-01 1.62467176e-02 4.13009254e-03]\n  Visits: 278, Total Value: 3344.699956457511\nChild Node Statistics:\n  Action: 0, Visits: 1, Total Value: 63.837493896484375 Avg Value: 63.83743005905432\n  Action: 1, Visits: 1, Total Value: 54.728126525878906 Avg Value: 54.72807179780711\n  Action: 2, Visits: 1, Total Value: 18.85460662841797 Avg Value: 18.854587773830197\n  Action: 3, Visits: 1, Total Value: 48.723106384277344 Avg Value: 48.723057661219684\n  Action: 4, Visits: 271, Total Value: -3803.687471432327 Avg Value: -14.035747075264133\n  Action: 5, Visits: 1, Total Value: 43.88111877441406 Avg Value: 43.881074893339175\n  Action: 6, Visits: 1, Total Value: 71.92572021484375 Avg Value: 71.92564828919546\nNode [4, 4, 4]  Statistics:\nNode value: -41.2598876953125\nNode policy: [0.01664829 0.84539721 0.0450549  0.03633273 0.02704742 0.00244039\n 0.02707906]\n  Visits: 271, Total Value: -3803.687471432327\nChild Node Statistics:\n  Action: 0, Visits: 2, Total Value: 55.395365142822264 Avg Value: 27.69766872257677\n  Action: 1, Visits: 86, Total Value: 2950.511590191717 Avg Value: 34.308273905621434\n  Action: 2, Visits: 50, Total Value: 633.8052089286624 Avg Value: 12.676103925051171\n  Action: 3, Visits: 104, Total Value: -62.1366166339224 Avg Value: -0.5974674618889898\n  Action: 4, Visits: 13, Total Value: 169.3633348965645 Avg Value: 13.027947836047437\n  Action: 5, Visits: 1, Total Value: 28.160797119140625 Avg Value: 28.16076895837167\n  Action: 6, Visits: 14, Total Value: 185.35040849924087 Avg Value: 13.239313947137639\nagent:  4\nmcts:  4\nsolver:  4\n","output_type":"stream"}],"execution_count":159},{"cell_type":"code","source":"if best_agent is not None:\n    mcts_df = evaluate_best_agent_mcts(best_agent)\nelse:\n    mcts_df = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:18:39.402209Z","iopub.execute_input":"2025-04-14T19:18:39.402579Z","iopub.status.idle":"2025-04-14T19:20:59.629484Z","shell.execute_reply.started":"2025-04-14T19:18:39.402550Z","shell.execute_reply":"2025-04-14T19:20:59.627941Z"},"_kg_hide-output":true},"outputs":[{"name":"stdout","text":"MCTS Episode 1 vs Solver_0.0: agent_first=True\n-----------------\n| x o   x o o o |\n| o x   x o x x |\n| x o   o x x o |\n| o x   x o x x |\n| o o o o x o o |\n| o x x x o x x |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 0, 'draws_1st': 0, 'loses_1st': 1, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 0}})\nMCTS Episode 2 vs Solver_0.0: agent_first=False\n-----------------\n| o   x x   o x |\n| x   x x x x o |\n| o   x o o o x |\n| x   o x x o o |\n| x   x o o x o |\n| o   o x o o x |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 0, 'draws_1st': 0, 'loses_1st': 1, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 1}})\nMCTS Episode 3 vs Solver_0.0: agent_first=True\n-----------------\n| o x x o o o o |\n| x x o x x x o |\n| o x x o o x x |\n| x o o x x o o |\n| o x x o o x x |\n| x o o x x o o |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 0, 'draws_1st': 0, 'loses_1st': 2, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 1}})\nMCTS Episode 4 vs Solver_0.0: agent_first=False\n-----------------\n| o   x x   x x |\n| o   x x   x x |\n| o x x o   o o |\n| x o o x   x x |\n| o x x o   o x |\n| o o o x o o o |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 0, 'draws_1st': 0, 'loses_1st': 2, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 2}})\nMCTS Episode 5 vs Solver_0.0: agent_first=True\n-----------------\n|       o o o o |\n|       x o x x |\n|       o x x o |\n|     x x o o x |\n|     o o x o x |\n|   x o x o x x |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 0, 'draws_1st': 0, 'loses_1st': 3, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 2}})\nMCTS Episode 6 vs Solver_0.0: agent_first=False\n-----------------\n| x   x x   o o |\n| o   x x x x x |\n| o   x o o o x |\n| x   o x x o o |\n| o x x o o x x |\n| o o o x o o x |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 0, 'draws_1st': 0, 'loses_1st': 3, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 3}})\nMCTS Episode 7 vs Solver_0.0: agent_first=True\n-----------------\n| o o x x o x x |\n| x x o x x o o |\n| o x x o o x x |\n| x o x x x o o |\n| o x o o o x o |\n| o o x x x o o |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 0, 'draws_1st': 1, 'loses_1st': 3, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 3}})\nMCTS Episode 8 vs Solver_0.0: agent_first=False\n-----------------\n|       o       |\n|     x x x x   |\n|     o o o x   |\n|     x x o o   |\n|     o o x x o |\n|     o x o x x |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 0, 'draws_1st': 1, 'loses_1st': 3, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 4}})\nMCTS Episode 9 vs Solver_0.0: agent_first=True\n-----------------\n| x x   o x x x |\n| o o x x x x o |\n| x x o o o x x |\n| o o x x x o o |\n| o x o o o x x |\n| o o x x o o o |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 1, 'draws_1st': 1, 'loses_1st': 3, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 4}})\nMCTS Episode 10 vs Solver_0.0: agent_first=False\n-----------------\n| x   o x   x   |\n| o   x x x x   |\n| o   x o o o x |\n| x   o x x x o |\n| x   x o o o x |\n| o   o x o o o |\n-----------------\ndefaultdict(<function evaluate_best_agent_mcts.<locals>.<lambda> at 0x7f1c244a9630>, {'Solver_0.0': {'wins_1st': 1, 'draws_1st': 1, 'loses_1st': 3, 'wins_2nd': 0, 'draws_2nd': 0, 'loses_2nd': 5}})\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-161-467f83e3e540>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbest_agent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmcts_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_best_agent_mcts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmcts_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-160-b1501e787004>\u001b[0m in \u001b[0;36mevaluate_best_agent_mcts\u001b[0;34m(best_agent, num_episodes)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0magent_first\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0magent_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# Use MCTS to select the best move\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_solver_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_history_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-158-5a7c60354c7d>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, initial_env, verbose)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\ndone\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-158-5a7c60354c7d>\u001b[0m in \u001b[0;36m_simulate\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mcurrent_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mleaf_node_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_and_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_node_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mleaf_node_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-158-5a7c60354c7d>\u001b[0m in \u001b[0;36mget_value_and_policy\u001b[0;34m(self, agent, temperature)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_value_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_temperature_to_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-9fe489ffcebe>\u001b[0m in \u001b[0;36mget_value_policy\u001b[0;34m(model, state)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_value_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs_as_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprobs_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mget_distribution\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \"\"\"\n\u001b[1;32m    712\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi_features_extractor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mlatent_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_action_dist_from_latent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_pi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/torch_layers.py\u001b[0m in \u001b[0;36mforward_actor\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_critic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":161},{"cell_type":"code","source":"mcts_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T17:41:41.891246Z","iopub.execute_input":"2025-04-14T17:41:41.891620Z","iopub.status.idle":"2025-04-14T17:41:41.917990Z","shell.execute_reply.started":"2025-04-14T17:41:41.891589Z","shell.execute_reply":"2025-04-14T17:41:41.917002Z"}},"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"      Opponent  Wins_1st  Draws_1st  Loses_1st  Wins_2nd  Draws_2nd  Loses_2nd\n0   Solver_0.0         0          0          5         0          0          5\n1   Solver_0.1         0          0          5         0          0          5\n2  Solver_0.15         0          0          5         0          0          5\n3   Solver_0.2         0          0          5         0          0          5\n4   Solver_0.3         0          0          5         0          0          5\n5   Solver_0.5         1          0          4         0          0          5\n6   Solver_1.0         0          0          5         1          0          4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Opponent</th>\n      <th>Wins_1st</th>\n      <th>Draws_1st</th>\n      <th>Loses_1st</th>\n      <th>Wins_2nd</th>\n      <th>Draws_2nd</th>\n      <th>Loses_2nd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Solver_0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Solver_0.1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Solver_0.15</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Solver_0.2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Solver_0.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Solver_0.5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Solver_1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":65}]}